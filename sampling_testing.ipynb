{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "from torchvision import transforms as T, utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ab diffusion related imports\n",
    "from AB_diffusion.user_hints import RandomHintGenerator\n",
    "from AB_diffusion.color_handling import de_normalize_lab, normalize_lab,plotMinMax\n",
    "from AB_diffusion.ab_denoising_diffusion_pytorch import ABUnet, ABGaussianDiffusion\n",
    "from AB_diffusion.ab_trainer import ABDataset\n",
    "from AB_diffusion.colorizer_app import ColorizerApp\n",
    "from IPython.utils import io as iol\n",
    "from skimage import io\n",
    "from kornia.color import rgb_to_lab, lab_to_rgb\n",
    "from datasets import load_from_disk,load_dataset\n",
    "#from ab_classifier_free_guidance import *\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "import random\n",
    "import glob\n",
    "import mplcursors\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "#import ipywidgets as widgets\n",
    "#from IPython.display import display, clear_output\n",
    "#from PIL import Image\n",
    "#import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "Selected GPU: A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(1 if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(\"Selected GPU:\", torch.cuda.get_device_name(device))\n",
    "#check wicj gpu is selected\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps 1000\n"
     ]
    }
   ],
   "source": [
    "from ema_pytorch import EMA\n",
    "\n",
    "\n",
    "def load(model_name,folder):\n",
    "    print(str(folder  + f'/{model_name}'))\n",
    "    data = torch.load(str(folder  + f'/{model_name}'), map_location=device)\n",
    "    return data\n",
    "\n",
    "model = ABUnet(\n",
    "    dim = 64,\n",
    "    out_dim = 2,\n",
    "    channels=5,\n",
    "    full_attn = (False, False, False, True)    \n",
    "\n",
    ").to(device)\n",
    "diffusion = ABGaussianDiffusion(\n",
    "    model,\n",
    "        image_size = 256,\n",
    "        timesteps = 1000,\n",
    "        objective = 'pred_v',\n",
    "        beta_schedule = 'sigmoid',\n",
    "        min_snr_loss_weight = True, # https://arxiv.org/abs/2303.09556\n",
    "        min_snr_gamma = 5,\n",
    "        offset_noise_strength=0.1\n",
    ").to(device)\n",
    "with iol.capture_output() as captured:\n",
    "\n",
    "    model_folder = \"./results/fs_imgnet-pred_v-1000-sigmoid-256\"\n",
    "    model_name = \"model-pred_v-1000-sigmoid-256-10x10000steps.pt\"\n",
    "    #model_folder = \"./results/no_reinit-pred_v-1000-sigmoid-256\"\n",
    "    #model_name = \"model-pred_v-1000-sigmoid-256-121x1000steps.pt\"\n",
    "    loaded_data = load(model_name,model_folder)\n",
    "    #diffusion_model.load_state_dict(loaded_data['model'])\n",
    "    #diffusion_model.to(device)\n",
    "    ema = EMA(diffusion)\n",
    "    ema.load_state_dict(loaded_data['ema'])\n",
    "    ema.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./experiments/comp/tennis.jfif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce45125fa724faa8affbfa2cfd3956c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Label(value='Input Image'), Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\xâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colorizer = ColorizerApp(path, ema,256, device)\n",
    "colorizer.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
