{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "from torchvision import transforms as T, utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from denoising_diffusion_pytorch.version import __version__\n",
    "\n",
    "#ab diffusion related imports\n",
    "from AB_diffusion.user_hints import RandomHintGenerator, get_color_hints \n",
    "from AB_diffusion.color_handling import de_normalize_lab, normalize_lab,plotMinMax\n",
    "from AB_diffusion.ab_denoising_diffusion_pytorch import ABUnet, ABGaussianDiffusion\n",
    "from AB_diffusion.ab_trainer import ABDataset\n",
    "from IPython.utils import io as iol\n",
    "from skimage import io\n",
    "from kornia.color import rgb_to_lab, lab_to_rgb\n",
    "from datasets import load_from_disk,load_dataset\n",
    "#from ab_classifier_free_guidance import *\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "import random\n",
    "import glob\n",
    "import mplcursors\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected GPU: A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "model_folder = \"./models\"\n",
    "model_name = \"v_pred_256_1000_cosine_13k_fine_tune.pt\"\n",
    "device = torch.device(6 if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Selected GPU:\", torch.cuda.get_device_name(device))\n",
    "#check wicj gpu is selected\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling timesteps 1000\n",
      "timesteps 1000\n"
     ]
    }
   ],
   "source": [
    "unet = ABUnet(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    out_dim = 2,\n",
    "    channels=5\n",
    "    )\n",
    "\n",
    "def load(model_name):\n",
    "    print(str(model_folder  + f'/{model_name}'))\n",
    "    data = torch.load(str(model_folder  + f'/{model_name}'), map_location=device)\n",
    "    return data\n",
    "\n",
    "diffusion_model = ABGaussianDiffusion(\n",
    "        unet,\n",
    "        image_size = 256,\n",
    "        timesteps = 1000,\n",
    "        objective = 'pred_v',\n",
    "        beta_schedule = 'cosine',\n",
    "        min_snr_loss_weight = False,\n",
    ")\n",
    "with iol.capture_output() as captured:\n",
    "    loaded_data = load(model_name)\n",
    "    diffusion_model.load_state_dict(loaded_data['model'])\n",
    "    diffusion_model.to(device)\n",
    "#make it not print from this cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset imagenet-1k (/Home/siv32/eve036/.cache/huggingface/datasets/imagenet-1k/default/1.0.0/a1e9bfc56c3a7350165007d1176b15e9128fcaf9ab972147840529aed3ae52bc)\n"
     ]
    }
   ],
   "source": [
    "#test_folder = \"./data/sem images/val\"\n",
    "#\n",
    "dataset_test = load_dataset(\"imagenet-1k\",split=\"validation\")\n",
    "#image_dir_val = \"./data/sem images/val\"\n",
    "\n",
    "\n",
    "#dataset_test = load_dataset(\"imagefolder\", data_dir=image_dir_val)[\"train\"]\n",
    "dataset = ABDataset(dataset_test,image_size=64)\n",
    "dataloader = DataLoader(dataset, batch_size = 1, shuffle = True, pin_memory = True,num_workers=100//6)\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FEF3C03D080>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#img = Image.open(\"./test_img.png\")\n",
    "##convert to torch tensor\n",
    "#img\n",
    "imgL, imgAB = next(iter(dataloader))\n",
    "\n",
    "#cat them together, convert to rgb and display\n",
    "imgLAB = torch.cat((imgL,imgAB),dim=1)\n",
    "imgRGB = transforms.ToPILImage()(\n",
    "            lab_to_rgb(\n",
    "                de_normalize_lab(imgLAB).squeeze(0).detach().cpu()\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "imgRGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.color as skcolor\n",
    "\n",
    "import kornia.color as kacolor\n",
    "from ipyevents import Event\n",
    "import io\n",
    "\n",
    "\n",
    "class ModelWrapper:\n",
    "    def __init__(self, model, device=\"cpu\"):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def colorize(self, input_image_L_tensor, user_hints_tensor, output_count):\n",
    "        conditioning = torch.cat([input_image_L_tensor, user_hints_tensor], dim=1)\n",
    "        conditioning = conditioning.repeat(output_count, 1, 1, 1)\n",
    "        conditioning = normalize_lab(conditioning)\n",
    "        output_AB = self.model.sample(conditioning.to(self.device))\n",
    "\n",
    "        self.colorization_LAB_tensor = de_normalize_lab(torch.cat([conditioning[:, :1, :, :], output_AB.to(\"cpu\")], dim=1))\n",
    "\n",
    "    \n",
    "class ImageProcessor:\n",
    "    def __init__(self, image):\n",
    "        self.image = image.copy()\n",
    "        self.input_image_LAB_tensor = self.convert_to_lab_tensor(self.image.copy())\n",
    "        self.input_image_L_tensor = self.input_image_LAB_tensor[:, :1, :, :]\n",
    "        self.user_hints_tensor = torch.zeros_like(self.input_image_LAB_tensor[:, 1:, :, :])\n",
    "        \n",
    "        self.point_color_conversions = PointColorConversions()\n",
    "\n",
    "    def convert_to_lab_tensor(self, image):\n",
    "        return kacolor.rgb_to_lab(transforms.ToTensor()(image).unsqueeze(0))\n",
    "\n",
    "    def lab_tensor_to_image(self, lab_tensor):\n",
    "        output_image = transforms.ToPILImage()(kacolor.lab_to_rgb (lab_tensor.squeeze(0).detach().cpu()))\n",
    "        return output_image\n",
    "\n",
    "    def apply_hints_to_image(self, x, y, color, sampling_size):\n",
    "        # Your existing code here, modified to work with the new structure.\n",
    "        # The code should update self.user_hints_tensor based on the x, y, color, and sampling_size parameters.    \n",
    "        color_lab = self.point_color_conversions.hex_to_lab(color)\n",
    "        print(color)\n",
    "        print(color_lab)\n",
    "        print(sampling_size)\n",
    "        print(x)\n",
    "        print(y)\n",
    "\n",
    "    \n",
    "        half_sampling = sampling_size // 2\n",
    "\n",
    "        x_start = max(0, x - half_sampling)\n",
    "        y_start = max(0, y - half_sampling)\n",
    "        x_end = min(self.image.width, x + half_sampling)\n",
    "        y_end = min(self.image.height, y + half_sampling)\n",
    "    \n",
    "        # Create blank image tensor\n",
    "        # Apply color to image tensor\n",
    "        self.user_hints_tensor[:,0,y_start:y_end,x_start:x_end] = color_lab[1]\n",
    "        self.user_hints_tensor[:,1,y_start:y_end,x_start:x_end] = color_lab[2]\n",
    "\n",
    "\n",
    "    def clear_inputs(self):\n",
    "        self.user_hints_tensor = torch.zeros_like(self.user_hints_tensor)\n",
    "\n",
    "    def get_input_tensors(self):\n",
    "        return self.input_image_L_tensor, self.user_hints_tensor\n",
    "\n",
    "    def get_input_image(self):\n",
    "        return self.image\n",
    "\n",
    "    def get_hinted_image(self):\n",
    "        temp_lab = torch.cat([self.input_image_L_tensor, self.user_hints_tensor], dim=1)\n",
    "        return self.lab_tensor_to_image(temp_lab)\n",
    "\n",
    "class WidgetManager:\n",
    "    def __init__(self, image_processor, model_wrapper):\n",
    "        self.image_processor = image_processor\n",
    "        self.model_wrapper = model_wrapper\n",
    "        \n",
    "        self.colorized_images_bytes = None\n",
    "\n",
    "        self.image_widget = self.create_image_widget()\n",
    "        self.main_colorized_image_widget = self.create_main_colorized_image_widget()\n",
    "        self.colorized_image_grid = self.create_colorized_image_grid()\n",
    "        self.color_picker = self.create_color_picker()\n",
    "        self.hint_size_slider = self.create_hint_size_slider()\n",
    "        self.output_count_slider = self.create_output_count_slider()\n",
    "        self.colorize_button = self.create_colorize_button()\n",
    "        self.clear_button = self.create_clear_button()\n",
    "        self.export_button = self.create_export_button()\n",
    "    \n",
    "    \n",
    "\n",
    "    def display(self):\n",
    "\n",
    "        # Create labels\n",
    "        input_image_label = widgets.Label('Input Image')\n",
    "        colorization_label = widgets.Label('Colorization')\n",
    "\n",
    "        # Create a layout for original and colorized images\n",
    "        input_image_box = widgets.VBox([input_image_label, self.image_widget])\n",
    "\n",
    "        # Put the colorized image grid in a VBox with an empty Label to push it to the bottom\n",
    "        colorized_image_grid_box = widgets.VBox([widgets.Label('Click to select'), self.colorized_image_grid])\n",
    "    \n",
    "        # Create a box for the main colorized image and the grid\n",
    "        colorization_box = widgets.HBox([widgets.VBox([colorization_label, self.main_colorized_image_widget]), colorized_image_grid_box], box_style='info')\n",
    "\n",
    "        image_layout = widgets.HBox([\n",
    "            input_image_box,\n",
    "            colorization_box, \n",
    "        ])\n",
    "\n",
    "        # Create a layout for the controls\n",
    "        control_layout = widgets.VBox([\n",
    "            self.color_picker, \n",
    "            self.hint_size_slider, \n",
    "            self.output_count_slider, \n",
    "            self.colorize_button,\n",
    "            self.clear_button,\n",
    "            self.export_button,\n",
    "        ])\n",
    "\n",
    "        # Combine the layouts\n",
    "        layout = widgets.VBox([image_layout,control_layout])\n",
    "\n",
    "        # Display the layout\n",
    "        display(layout)\n",
    "    def create_colorized_image_grid(self):\n",
    "        colorized_image_grid = widgets.GridBox([], layout=widgets.Layout(grid_template_columns=\"repeat(3, 100px)\"),align_items='center')\n",
    "        return colorized_image_grid\n",
    "\n",
    "    def create_main_colorized_image_widget(self):\n",
    "        main_colorized_image_widget = widgets.Image(format='png',description='Colorized Image')\n",
    "        main_colorized_image_widget.layout = widgets.Layout(object_fit='contain', height='auto', width='300px')\n",
    "        return main_colorized_image_widget\n",
    "    \n",
    "    def create_image_widget(self):\n",
    "        \n",
    "        image_widget = widgets.Image(format='png',description='Input Image')\n",
    "\n",
    "        image_widget.layout = widgets.Layout(object_fit='contain', height='auto', width='300px')\n",
    "        # Set the initial image data\n",
    "        image_widget.value = self.to_bytes(self.image_processor.get_input_image())\n",
    "\n",
    "        event = Event(source=image_widget, watched_events=['click'])\n",
    "        event.on_dom_event(self.on_image_click)\n",
    "\n",
    "        return image_widget\n",
    "    \n",
    "    def create_color_picker(self):\n",
    "        color_picker = widgets.ColorPicker(value='#000000', description='Color:')\n",
    "        return color_picker\n",
    "    def create_hint_size_slider(self):\n",
    "        hint_size_slider = widgets.IntSlider(value=4, min=2, max=10, description='Hint Size:')\n",
    "        return hint_size_slider\n",
    "    def create_output_count_slider(self):\n",
    "        output_count_slider = widgets.IntSlider(value=1, min=1, max=10, description='Output Count:')\n",
    "        return output_count_slider\n",
    "    \n",
    "    def create_colorize_button(self):\n",
    "        colorize_button = widgets.Button(description='Colorize!')\n",
    "        colorize_button.on_click(self.on_colorize_button_click)\n",
    "        return colorize_button\n",
    "    def create_clear_button(self):\n",
    "        clear_button = widgets.Button(description='Clear')\n",
    "        clear_button.on_click(self.on_clear_button_click)\n",
    "        return clear_button\n",
    "    \n",
    "    def create_export_button(self):\n",
    "        self.export_filename_text = widgets.Text(value='output.png', description='Filename:')\n",
    "        export_button = widgets.Button(description='Export')\n",
    "        export_button.on_click(self.on_export_button_click)\n",
    "        return widgets.VBox([self.export_filename_text, export_button])\n",
    "\n",
    "    def on_export_button_click(self, _):\n",
    "        # Get the image data from the widget\n",
    "        image_data = self.main_colorized_image_widget.value\n",
    "\n",
    "        # Check if image_data is not empty\n",
    "        if not image_data:\n",
    "            print(\"No image data to export.\")\n",
    "            return\n",
    "\n",
    "        # Convert the image data to a PIL Image\n",
    "        try:\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "        except IOError:\n",
    "            print(\"Cannot convert image data to PIL Image. The data may not be in a valid image format.\")\n",
    "            return\n",
    "\n",
    "        # Save the image with the filename from the text widget\n",
    "        filename = self.export_filename_text.value\n",
    "        try:\n",
    "            image.save(filename)\n",
    "            print(f\"Image exported as {filename}.\")\n",
    "        except IOError:\n",
    "            print(f\"Cannot save image as {filename}.\")\n",
    "\n",
    "    def create_colorized_image_widget(self, image_bytes):\n",
    "        img_widget = widgets.Image(value=image_bytes, format='png')\n",
    "        img_widget.layout = widgets.Layout(object_fit='contain', height='auto', width='100px')\n",
    "    \n",
    "        def on_click(event):\n",
    "            self.on_additional_colorization_click(image_bytes)\n",
    "\n",
    "        event_handler = Event(source=img_widget, watched_events=['click'])\n",
    "        event_handler.on_dom_event(on_click)\n",
    "\n",
    "        return img_widget\n",
    "\n",
    "    def on_clear_button_click(self, _):\n",
    "        self.image_processor.clear_inputs()\n",
    "        self.image_widget.value = self.to_bytes(self.image_processor.get_hinted_image())\n",
    "    \n",
    "\n",
    "\n",
    "    def on_colorize_button_click(self, _):\n",
    "        input_image_L_tensor, user_hints_tensor = self.image_processor.get_input_tensors()\n",
    "        output_count = self.output_count_slider.value\n",
    "    \n",
    "        self.model_wrapper.colorize(input_image_L_tensor, user_hints_tensor, output_count)\n",
    "    \n",
    "        model_output_LAB_tensor = self.model_wrapper.colorization_LAB_tensor\n",
    "        # Convert the colorized images from tensors to PIL images, and then to bytes\n",
    "        self.colorized_images_bytes = [self.to_bytes(self.image_processor.lab_tensor_to_image(img)) for img in model_output_LAB_tensor]\n",
    "    \n",
    "        # Update the main colorized image widget with the first colorized image\n",
    "        self.main_colorized_image_widget.value = self.colorized_images_bytes[0]\n",
    "    \n",
    "        # Create an image widget for each additional colorization\n",
    "        additional_colorizations_widgets = []\n",
    "\n",
    "        if output_count > 1:\n",
    "            for img_bytes in self.colorized_images_bytes:\n",
    "                img_widget = self.create_colorized_image_widget(img_bytes)\n",
    "                additional_colorizations_widgets.append(img_widget)\n",
    "    \n",
    "        # Update the grid with the additional colorizations\n",
    "        self.colorized_image_grid.children = additional_colorizations_widgets\n",
    "    \n",
    "    def on_additional_colorization_click(self, image_bytes):\n",
    "        # Update the main colorized image widget with the clicked image\n",
    "        self.main_colorized_image_widget.value = image_bytes\n",
    "    \n",
    "    def on_image_click(self, event):\n",
    "        x = event['dataX']\n",
    "        y = event['dataY']\n",
    "        color = self.color_picker.value\n",
    "        sampling_size = self.hint_size_slider.value\n",
    "\n",
    "        self.image_processor.apply_hints_to_image(x, y, color, sampling_size)\n",
    "\n",
    "        hinted_image = self.image_processor.get_hinted_image()\n",
    "        self.image_widget.value = self.to_bytes(hinted_image)\n",
    "    def to_bytes(self, pil_image):\n",
    "        byte_arr = io.BytesIO()\n",
    "        pil_image.save(byte_arr, format='PNG')\n",
    "        return byte_arr.getvalue()\n",
    "\n",
    "class ColorizerApp:\n",
    "    def __init__(self, image, model, device=\"cpu\"):\n",
    "        self.image_processor = ImageProcessor(image)\n",
    "        self.model_wrapper = ModelWrapper(model, device)\n",
    "        self.widget_manager = WidgetManager(self.image_processor, self.model_wrapper)\n",
    "\n",
    "    def run(self):\n",
    "        self.widget_manager.display()\n",
    "\n",
    "class PointColorConversions:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def rgb_to_hex(self, color_rgb):\n",
    "        return '#%02x%02x%02x' % color_rgb\n",
    "    \n",
    "    def hex_to_rgb(self, color_hex):\n",
    "        color_hex = color_hex.lstrip('#')\n",
    "        return tuple(int(color_hex[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "    def rgb_to_lab(self, color_rgb):\n",
    "        color_rgb = np.array(color_rgb).reshape(1, 1, 3) / 255.0\n",
    "        color_lab = skcolor.rgb2lab(color_rgb)\n",
    "        return tuple(color_lab[0, 0])\n",
    "\n",
    "    def lab_to_rgb(self, color_lab):\n",
    "        color_lab = np.array(color_lab).reshape(1, 1, 3)\n",
    "        color_rgb = skcolor.lab2rgb(color_lab)\n",
    "        return tuple((color_rgb[0, 0] * 255).astype(int))\n",
    "\n",
    "    def hex_to_lab(self, color_hex):\n",
    "        color_rgb = np.array(self.hex_to_rgb(color_hex)) / 255.0\n",
    "        return skcolor.rgb2lab(color_rgb.reshape(1, 1, 3))[0, 0]\n",
    "\n",
    "    def lab_to_hex(self, color_lab):\n",
    "        color_rgb = self.lab_to_rgb(color_lab)\n",
    "        return self.rgb_to_hex(color_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b43f98e1bf4c17b7a63b8cc09471e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Label(value='Input Image'), Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5841235cabe044e9a9d743d038d3a495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "colorizer = ColorizerApp(imgRGB, diffusion_model, device)\n",
    "\n",
    "colorizer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hintgen = RandomHintGenerator(\n",
    "    input_size = 256,\n",
    "    hint_size =4)\n",
    "\n",
    "masks = hintgen(batch_size = 1)\n",
    "hints = get_color_hints(imgAB = imgAB, hints = masks, avg_color = True)\n",
    "imgLAB_w_hints = torch.cat((imgL,hints),dim=1)\n",
    "hintsRGB = transforms.ToPILImage()(\n",
    "            lab_to_rgb(\n",
    "                de_normalize_lab(imgLAB_w_hints).detach().cpu()\n",
    "            ).squeeze(0)\n",
    "        )\n",
    "hintsRGB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputAB = diffusion_model.sample(imgLAB_w_hints.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpuLAB = torch.cat((imgL,outputAB.to(\"cpu\")),dim=1)\n",
    "outputRGB = transforms.ToPILImage()(\n",
    "            lab_to_rgb(\n",
    "                de_normalize_lab(outpuLAB).detach().cpu()\n",
    "            ).squeeze(0))\n",
    "\n",
    "\n",
    "outputRGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_dimensions(W, H, h):\n",
    "    # calculate the new width while preserving the aspect ratio\n",
    "    w = int((W * h) / H)\n",
    "    # adjust the width to be divisible by 2 three times\n",
    "    while w % 8 != 0:\n",
    "        w -= 1\n",
    "    return h, w\n",
    "#convert to torch tensor\n",
    "imgRGB = transforms.ToTensor()(img)\n",
    "imgL = rgb_to_lab(imgRGB)[:1,:,:]\n",
    "\n",
    "\n",
    "original_height, original_width = imgRGB.shape[1:]\n",
    "print(\"original dimensions: \", original_height, original_width)\n",
    "new_height, new_width = get_new_dimensions(original_width, original_height, 256)\n",
    "\n",
    "imgRGB = transforms.Resize((new_height, new_width))(imgRGB)\n",
    "print(\"new dimensions: \", imgRGB.shape[1:])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use ipywigdet linemagi\n",
    "testImg = jimg#transforms.ToPILImage()(jimg)\n",
    "testImg = testImg.convert('L').convert('RGB')\n",
    "\n",
    "jupyter_colorizer = JupyterImageColorizer(testImg, diffusion_model,device=device)\n",
    "jupyter_colorizer.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7e-5+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorizations_LAB = jupyter_colorizer.output_image_LAB_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorizations_LAB =  transforms.Resize((original_height,original_width))(colorizations_LAB)\n",
    "print(imgL.shape)\n",
    "colorizations_LAB[:1,:1,:,:] = imgL\n",
    "\n",
    "transforms.ToPILImage()(lab_to_rgb(colorizations_LAB).squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
