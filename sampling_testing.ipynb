{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "from torchvision import transforms as T, utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from denoising_diffusion_pytorch.version import __version__\n",
    "\n",
    "#ab diffusion related imports\n",
    "from user_hints import *\n",
    "from color_handling import de_normalize, normalize_lab, LAB2RGB\n",
    "from IPython.utils import io as iol\n",
    "from skimage import io\n",
    "from kornia.color import rgb_to_lab, lab_to_rgb\n",
    "from datasets import load_from_disk,load_dataset\n",
    "from ab_trainer import *\n",
    "#from ab_classifier_free_guidance import *\n",
    "\n",
    "from ab_denoising_diffusion_pytorch import *\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "import random\n",
    "import glob\n",
    "import mplcursors\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ImageSampler:\n",
    "    def __init__(self, image, model, sampling_size=2, device=\"cpu\"):\n",
    "        self.image = image.copy()\n",
    "        self.device = device\n",
    "        self.input_image_displayed = image.copy()\n",
    "        self.output_image_displayed = image.copy()\n",
    "        self.input_LAB_tensor = normalize_lab(rgb_to_lab(transforms.ToTensor()(self.input_image_displayed)).unsqueeze(0))\n",
    "        self.output_LAB_tensor = normalize_lab(rgb_to_lab(transforms.ToTensor()(self.output_image_displayed)).unsqueeze(0))\n",
    "        self.model = model\n",
    "        self.sampling_size = sampling_size\n",
    "        self.selected_color = (0, 0, 0)  # Default color is black\n",
    "        \n",
    "        self.fig, (self.input_ax, self.output_ax) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        \n",
    "        self.output = widgets.Output()\n",
    "        self.slider = widgets.IntSlider(value=self.sampling_size, min=1, max=10, description='Sampling Size:')\n",
    "        self.color_picker = widgets.ColorPicker(value=self.rgb_to_hex(self.selected_color), description='Color:')\n",
    "        self.colorize_button = widgets.Button(description='Colorize!')\n",
    "        self.clear_button = widgets.Button(description='Clear')\n",
    "        self.colorize_button.on_click(self.colorize)\n",
    "        self.clear_button.on_click(self.clear_inputs)\n",
    "        \n",
    "    def display(self):\n",
    "        self.input_ax.set_title('Grayscale Image')\n",
    "        self.output_ax.set_title('Output Image')\n",
    "\n",
    "        self.fig.canvas.mpl_connect('button_press_event', self.on_image_click)\n",
    "        self.output_ax.set_axis_off()\n",
    "        self.slider.observe(self.on_slider_change, names='value')\n",
    "        self.color_picker.observe(self.on_color_pick, names='value')\n",
    "        \n",
    "        vbox = widgets.VBox([self.fig.canvas, self.slider, self.color_picker, self.colorize_button, self.clear_button])\n",
    "        display(vbox)\n",
    "        self.draw_images()\n",
    "        \n",
    "    def on_slider_change(self, change):\n",
    "        self.sampling_size = change.new\n",
    "        \n",
    "    def on_color_pick(self, change):\n",
    "        color_hex = change.new\n",
    "        self.selected_color = self.hex_to_rgb(color_hex)\n",
    "        \n",
    "    def displayed_img_to_data(self):\n",
    "        self.input_LAB_tensor = normalize_lab(rgb_to_lab(transforms.ToTensor()(self.input_image_displayed).unsqueeze(0))).to(self.device)\n",
    "        self.output_LAB_tensor = normalize_lab(rgb_to_lab(transforms.ToTensor()(self.output_image_displayed).unsqueeze(0))).to(self.device)\n",
    "        \n",
    "    def data_to_displayed_img(self):\n",
    "        self.input_image_displayed = transforms.ToPILImage()(\n",
    "            lab_to_rgb(\n",
    "                de_normalize(self.input_LAB_tensor).squeeze(0).detach().cpu()\n",
    "            )\n",
    "        )\n",
    "        self.output_image_displayed = transforms.ToPILImage()(\n",
    "            lab_to_rgb(\n",
    "                de_normalize(self.output_LAB_tensor).squeeze(0).detach().cpu()\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def draw_images(self):\n",
    "        self.data_to_displayed_img()\n",
    "        self.displayed_img_to_data()\n",
    "        self.input_ax.imshow(self.input_image_displayed)\n",
    "        self.fig.canvas.draw_idle()\n",
    "        self.output_ax.imshow(self.output_image_displayed)\n",
    "        self.fig.canvas.draw_idle()\n",
    "        \n",
    "    def on_image_click(self, event):\n",
    "        if event.button == 1:  # Left mouse button clicked\n",
    "            x = int(event.xdata)\n",
    "            y = int(event.ydata)\n",
    "\n",
    "            half_sampling = self.sampling_size // 2\n",
    "            x_start = max(0, x - half_sampling)\n",
    "            y_start = max(0, y - half_sampling)\n",
    "            x_end = min(self.input_image_displayed.width, x + half_sampling)\n",
    "            y_end = min(self.input_image_displayed.height, y + half_sampling)\n",
    "\n",
    "            temp_rgb = self.input_image_displayed.copy()\n",
    "            for i in range(x_start, x_end):\n",
    "                for j in range(y_start, y_end):\n",
    "                    temp_rgb.putpixel((i, j), self.selected_color)\n",
    "            #\n",
    "            input_AB = normalize_lab(self.convert_to_lab_tensor(temp_rgb))[:, 1:, :, :]\n",
    "            #set all values in intput_AB that are not in the selected area to 0\n",
    "            self.input_LAB_tensor[:, 1:, :, :] = input_AB\n",
    "            self.draw_images()\n",
    "                \n",
    "    def colorize(self, _):\n",
    "        output_AB = self.model.sample(self.input_LAB_tensor)\n",
    "        self.output_LAB_tensor[:, 1:, :, :] = output_AB\n",
    "        self.draw_images()\n",
    "        \n",
    "    def convert_to_lab_tensor(self, image):\n",
    "        return rgb_to_lab(transforms.ToTensor()(image).unsqueeze(0))\n",
    "    \n",
    "    def clear_inputs(self, _):\n",
    "        self.input_image_displayed = self.image.copy()\n",
    "        self.input_LAB_tensor = normalize_lab(rgb_to_lab(transforms.ToTensor()(self.input_image_displayed)).unsqueeze(0))\n",
    "        self.draw_images()\n",
    "        \n",
    "    @staticmethod\n",
    "    def rgb_to_hex(color_rgb):\n",
    "        return '#%02x%02x%02x' % color_rgb\n",
    "    \n",
    "    @staticmethod\n",
    "    def hex_to_rgb(color_hex):\n",
    "        color_hex = color_hex.lstrip('#')\n",
    "        return tuple(int(color_hex[i:i+2], 16) for i in (0, 2, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = \"./results\"\n",
    "\n",
    "device = torch.device(6 if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Selected GPU:\", torch.cuda.get_device_name(device))\n",
    "#check wicj gpu is selected\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = ABUnet(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    out_dim = 2,\n",
    "    channels=5\n",
    "    )\n",
    "\n",
    "def load(milestone):\n",
    "    print(str(results_folder  + f'/model-{milestone}.pt'))\n",
    "    data = torch.load(str(results_folder  + f'/model-{milestone}.pt'), map_location=device)\n",
    "    return data\n",
    "\n",
    "diffusion_model = ABGaussianDiffusion(\n",
    "        unet,\n",
    "        image_size = 256,\n",
    "        timesteps = 1000,\n",
    "        objective = 'pred_v',\n",
    "        beta_schedule = 'cosine',\n",
    "        min_snr_loss_weight = False,\n",
    ")\n",
    "with iol.capture_output() as captured:\n",
    "    loaded_data = load(8)\n",
    "    diffusion_model.load_state_dict(loaded_data['model'])\n",
    "    diffusion_model.to(device)\n",
    "#make it not print from this cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = \"./data/sem images/val\"\n",
    "\n",
    "#dataset_test = load_dataset(\"imagenet-1k\",split=\"validation\")\n",
    "#dataset_test = load_dataset(\"image_folder\",data_files=test_folder)\n",
    "image_dir_val = \"./data/sem images/val\"\n",
    "\n",
    "\n",
    "dataset_val = load_dataset(\"imagefolder\", data_dir=image_dir_val)[\"train\"]\n",
    "dataset = ABDataset(dataset_val,image_size=256)\n",
    "dataloader = DataLoader(dataset, batch_size = 1, shuffle = True, pin_memory = True,num_workers=cpu_count()//6)\n",
    "imgL, imgAB = next(iter(dataloader))\n",
    "\n",
    "#cat them together, convert to rgb and display\n",
    "imgLAB = torch.cat((imgL,imgAB),dim=1)\n",
    "imgRGB = transforms.ToPILImage()(\n",
    "            lab_to_rgb(\n",
    "                de_normalize(imgLAB).squeeze(0).detach().cpu()\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "imgRGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "test_image = imgRGB.convert('L').convert('RGB')\n",
    "img_samp = ImageSampler(test_image, diffusion_model, sampling_size=2,device=device)\n",
    "img_samp.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = \"./results\"\n",
    "\n",
    "\n",
    "\n",
    "def load(milestone):\n",
    "    print(str(results_folder  + f'/model-{milestone}.pt'))\n",
    "    data = torch.load(str(results_folder  + f'/model-{milestone}.pt'), map_location=device)\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = ABUnet(\n",
    "    dim = 64,\n",
    "    out_dim = 2,\n",
    "    channels=5,    \n",
    "\n",
    ").to(device)\n",
    "diffusion = ABGaussianDiffusion(\n",
    "    unet,\n",
    "        image_size = 256,\n",
    "        timesteps = 1000,\n",
    "        objective = 'pred_v',\n",
    "        beta_schedule = 'cosine',\n",
    "        auto_normalize=False\n",
    ").to(device)\n",
    "\n",
    "hint_generator = RandomHintGenerator(\n",
    "    input_size = 256,\n",
    "    hint_size = 2,\n",
    "    num_hint_range = [0, 10]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample(model, dataloader = None, num_samples = 5,batch_size = 5,hint_generator = None,cond_scale = 1.0):\n",
    "    images_pred_list = []\n",
    "    images_hint_list = []\n",
    "    images_original_list = []  \n",
    "\n",
    "    batches = num_to_groups(num_samples, batch_size)\n",
    "    \n",
    "    \n",
    "    for i, b in enumerate(batches):\n",
    "        # one iteration of the dataloader\n",
    "        imgL, imgAB = next(iter(dataloader))\n",
    "\n",
    "        \n",
    "        imgL_batch = imgL[:b].to(device)\n",
    "        imgAB_batch = imgAB[:b].to(device)\n",
    "        imgAB = imgAB.to(device)\n",
    "        if hint_generator is not None:\n",
    "            hints_sample = hint_generator(imgL.shape[0])\n",
    "            hints_AB_sample = get_color_hints(imgAB,hints_sample,True,device)[:b].to(device)\n",
    "            conditioning = torch.cat([imgL_batch, hints_AB_sample[:b]], dim=1).to(device)\n",
    "        \n",
    "        \n",
    "        images_pred_list.append(torch.cat([imgL_batch, model.sample(conditioning)], dim=1))\n",
    "        images_hint_list.append(conditioning)\n",
    "        images_original_list.append(torch.cat([imgL_batch, imgAB_batch], dim=1))\n",
    "        \n",
    "        if hint_generator is not None:\n",
    "            images_hint_list_rgb = [torch.from_numpy(LAB2RGB(im.cpu())).permute(0,3,1,2).to(device) for im in images_hint_list]\n",
    "            images_hint_rgb= torch.cat(images_hint_list_rgb, dim = 0)\n",
    "            images_hint_grid = utils.make_grid(images_hint_rgb, nrow=int(math.sqrt(num_samples))).permute(1,2,0)\n",
    "        \n",
    "        \n",
    "        images_pred_list_rgb = [torch.from_numpy(LAB2RGB(im.cpu())).permute(0,3,1,2).to(device) for im in images_pred_list]\n",
    "        images_pred_rgb= torch.cat(images_pred_list_rgb, dim = 0)\n",
    "        images_original_list_rgb = [torch.from_numpy(LAB2RGB(im.cpu())).permute(0,3,1,2).to(device) for im in images_original_list]\n",
    "        images_original_rgb= torch.cat(images_original_list_rgb, dim = 0)\n",
    "        \n",
    "        images_original_grid = utils.make_grid(images_original_rgb, nrow=int(math.sqrt(num_samples))).permute(1,2,0)\n",
    "        images_pred_grid = utils.make_grid(images_pred_rgb, nrow=int(math.sqrt(num_samples))).permute(1,2,0)\n",
    "\n",
    "        #convert to numpy arrays    \n",
    "        images_pred_grid = images_pred_grid.cpu().detach().numpy()\n",
    "        images_original_grid = images_original_grid.cpu().detach().numpy()\n",
    "        images_hint_grid = images_hint_grid.cpu().detach().numpy()\n",
    "        #display the grid images\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(images_pred_grid)\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(images_original_grid)\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(images_hint_grid)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "loaded_data = load(8)\n",
    "diffusion.load_state_dict(loaded_data['model'])\n",
    "diffusion = diffusion.to(device)\n",
    "\n",
    "dataset_test = load_dataset(\"imagenet-1k\",split=\"validation\")\n",
    "dataset = ABDataset(dataset_test,image_size=256)\n",
    "dataloader = DataLoader(dataset, batch_size = 25, shuffle = True, pin_memory = True,num_workers=cpu_count()//6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go one step trough the dataloader and sample\n",
    "sample(diffusion,dataloader = dataloader, num_samples = 25,batch_size = 25,hint_generator = hint_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
